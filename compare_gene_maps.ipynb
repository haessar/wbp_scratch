{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "gene_maps_dir = \"data/gene_maps\"\n",
    "\n",
    "wbps_map = os.path.join(gene_maps_dir, \"previous_to_current_id.tsv\")\n",
    "lo_map = os.path.join(gene_maps_dir, \"gene_map.few_more.cc_uniq.tsv\")\n",
    "\n",
    "cols = (\"v18\", \"v19\", \"qual\")\n",
    "wbps_df = pd.read_csv(wbps_map, delimiter=\"\\t\", names=cols, index_col=0)\n",
    "wbps_df[\"source\"] = \"wbps\"\n",
    "lo_df = pd.read_csv(lo_map, delimiter=\"\\t\", names=cols, index_col=0)\n",
    "lo_df[\"source\"] = \"lo\"\n",
    "all_df = pd.concat([lo_df, wbps_df]).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_shared_and_unique(left_df, right_df):\n",
    "    shared_df = pd.DataFrame(index=left_df.index, columns=left_df.columns)\n",
    "    uniq_df = pd.DataFrame(index=left_df.index, columns=left_df.columns)\n",
    "    for idx, row in left_df.iterrows():\n",
    "        shared = False\n",
    "        if idx in right_df.index:\n",
    "            for i2, r2 in right_df[right_df.index==idx].iterrows():\n",
    "                if r2.v19 == row.v19:\n",
    "                    shared = True\n",
    "        if shared:\n",
    "            shared_df = pd.concat([shared_df, pd.DataFrame([row])])\n",
    "        else:\n",
    "            uniq_df = pd.concat([uniq_df, pd.DataFrame([row])])\n",
    "    return shared_df.dropna(), uniq_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mappings shared: 8345\n"
     ]
    }
   ],
   "source": [
    "shared_df, _ = split_shared_and_unique(wbps_df, lo_df)\n",
    "print(f\"mappings shared: {len(shared_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine unique mappings from forward and reverse Liftoff runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo_for_map = os.path.join(gene_maps_dir, \"gene_map_1.cc.tsv\")\n",
    "lo_for_df = pd.read_csv(lo_for_map, delimiter=\"\\t\", names=cols, index_col=0)\n",
    "lo_rev_map = os.path.join(gene_maps_dir, \"gene_map_0.cc.tsv\")\n",
    "lo_rev_df = pd.read_csv(lo_rev_map, delimiter=\"\\t\", names=cols, index_col=0)\n",
    "\n",
    "_, uniq_rev = split_shared_and_unique(lo_rev_df, lo_for_df)\n",
    "_, uniq_for = split_shared_and_unique(lo_for_df, lo_rev_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique mappings from forward Liftoff run (18 -> 19): 70\n",
      "...not in WBPS mapping: 56\n",
      "Unique mappings from reverse Liftoff run (19 -> 18): 76\n",
      "...not in WBPS mapping: 53\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique mappings from forward Liftoff run (18 -> 19): {len(uniq_for)}\")\n",
    "print(f\"...not in WBPS mapping: {len(uniq_for[~uniq_for.index.isin(wbps_df.index)])}\")\n",
    "print(f\"Unique mappings from reverse Liftoff run (19 -> 18): {len(uniq_rev)}\")\n",
    "print(f\"...not in WBPS mapping: {len(uniq_rev[~uniq_rev.index.isin(wbps_df.index)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how many v19 genes are missed by both mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gffutils\n",
    "import os.path\n",
    "\n",
    "v19_path = \"data/from_WBPS/strongyloides_stercoralis.PRJNA930454.WBPS19.annotations.gff3\"\n",
    "\n",
    "if not os.path.exists(\"v19.db\"):\n",
    "    db = gffutils.create_db(v19_path, \"v19.db\", merge_strategy=\"create_unique\")\n",
    "else:\n",
    "    db = gffutils.FeatureDB(\"v19.db\")\n",
    "\n",
    "missing_v19_lo = set()\n",
    "missing_v19_wbps = set()\n",
    "for g in db.all_features(featuretype=\"gene\"):\n",
    "    g_id = g.id.split(\":\")[1]\n",
    "    if lo_df[lo_df.v19 == g_id].empty:\n",
    "        missing_v19_lo.add(g_id)\n",
    "    if wbps_df[wbps_df.v19 == g_id].empty:\n",
    "        missing_v19_wbps.add(g_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total WBPS19 genes: 12061\n",
      "Missing from Liftoff mappings: 3141\n",
      "Missing from WBPS mappings: 2279\n",
      "Missing from both: 1953\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total WBPS19 genes: {len(list(db.all_features(featuretype='gene')))}\")\n",
    "print(f\"Missing from Liftoff mappings: {len(missing_v19_lo)}\")\n",
    "print(f\"Missing from WBPS mappings: {len(missing_v19_wbps)}\")\n",
    "print(f\"Missing from both: {len(missing_v19_lo.intersection(missing_v19_wbps))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(gene_maps_dir, \"missing_v19_ids.txt\"), \"w\") as f:\n",
    "    for g_id in sorted(missing_v19_lo.intersection(missing_v19_wbps)):\n",
    "        f.write(f\"{g_id}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how many v18 genes are missed by both mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m db\u001b[38;5;241m.\u001b[39mall_features(featuretype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     13\u001b[0m     g_id \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlo_df\u001b[49m[lo_df\u001b[38;5;241m.\u001b[39mv19 \u001b[38;5;241m==\u001b[39m g_id]\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     15\u001b[0m         missing_v19_lo\u001b[38;5;241m.\u001b[39madd(g_id)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wbps_df[wbps_df\u001b[38;5;241m.\u001b[39mv19 \u001b[38;5;241m==\u001b[39m g_id]\u001b[38;5;241m.\u001b[39mempty:\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m db\u001b[38;5;241m.\u001b[39mall_features(featuretype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     13\u001b[0m     g_id \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlo_df\u001b[49m[lo_df\u001b[38;5;241m.\u001b[39mv19 \u001b[38;5;241m==\u001b[39m g_id]\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     15\u001b[0m         missing_v19_lo\u001b[38;5;241m.\u001b[39madd(g_id)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wbps_df[wbps_df\u001b[38;5;241m.\u001b[39mv19 \u001b[38;5;241m==\u001b[39m g_id]\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/wbp_scratch/.venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/wbp_scratch/.venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gffutils\n",
    "\n",
    "v18_path = \"data/from_WBPS/strongyloides_stercoralis.PRJEB528.WBPS18.annotations.gff3\"\n",
    "\n",
    "if not os.path.exists(\"v18.db\"):\n",
    "    db = gffutils.create_db(v18_path, \"v18.db\", merge_strategy=\"create_unique\")\n",
    "else:\n",
    "    db = gffutils.FeatureDB(\"v18.db\")\n",
    "\n",
    "missing_v18_lo = set()\n",
    "missing_v18_wbps = set()\n",
    "for g in db.all_features(featuretype=\"gene\"):\n",
    "    g_id = g.id.split(\":\")[1]\n",
    "    if lo_df[lo_df.index == g_id].empty:\n",
    "        missing_v18_lo.add(g_id)\n",
    "    if wbps_df[wbps_df.index == g_id].empty:\n",
    "        missing_v18_wbps.add(g_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
