{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "gene_maps_dir = \"data/gene_maps\"\n",
    "\n",
    "wbps_map = os.path.join(gene_maps_dir, \"previous_to_current_id.tsv\")\n",
    "lo_map = os.path.join(gene_maps_dir, \"gene_map.few_more.cc_uniq.tsv\")\n",
    "\n",
    "cols = (\"v18\", \"v19\", \"qual\")\n",
    "wbps_df = pd.read_csv(wbps_map, delimiter=\"\\t\", names=cols, index_col=0)\n",
    "wbps_df[\"source\"] = \"wbps\"\n",
    "lo_df = pd.read_csv(lo_map, delimiter=\"\\t\", names=cols, index_col=0)\n",
    "lo_df[\"source\"] = \"lo\"\n",
    "all_df = pd.concat([lo_df, wbps_df]).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_shared_and_unique(left_df, right_df):\n",
    "    shared_df = pd.DataFrame(index=left_df.index, columns=left_df.columns)\n",
    "    uniq_df = pd.DataFrame(index=left_df.index, columns=left_df.columns)\n",
    "    for idx, row in left_df.iterrows():\n",
    "        shared = False\n",
    "        if idx in right_df.index:\n",
    "            for i2, r2 in right_df[right_df.index==idx].iterrows():\n",
    "                if r2.v19 == row.v19:\n",
    "                    shared = True\n",
    "        if shared:\n",
    "            shared_df = pd.concat([shared_df, pd.DataFrame([row])])\n",
    "        else:\n",
    "            uniq_df = pd.concat([uniq_df, pd.DataFrame([row])])\n",
    "    return shared_df.dropna(), uniq_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mappings shared: 8345\n"
     ]
    }
   ],
   "source": [
    "shared_df, _ = split_shared_and_unique(wbps_df, lo_df)\n",
    "print(f\"mappings shared: {len(shared_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine unique mappings from forward and reverse Liftoff runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo_for_map = os.path.join(gene_maps_dir, \"gene_map_1.cc.tsv\")\n",
    "lo_for_df = pd.read_csv(lo_for_map, delimiter=\"\\t\", names=cols, index_col=0)\n",
    "lo_rev_map = os.path.join(gene_maps_dir, \"gene_map_0.cc.tsv\")\n",
    "lo_rev_df = pd.read_csv(lo_rev_map, delimiter=\"\\t\", names=cols, index_col=0)\n",
    "\n",
    "_, uniq_rev = split_shared_and_unique(lo_rev_df, lo_for_df)\n",
    "_, uniq_for = split_shared_and_unique(lo_for_df, lo_rev_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique mappings from forward Liftoff run (18 -> 19): 70\n",
      "...not in WBPS mapping: 56\n",
      "Unique mappings from reverse Liftoff run (19 -> 18): 76\n",
      "...not in WBPS mapping: 53\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique mappings from forward Liftoff run (18 -> 19): {len(uniq_for)}\")\n",
    "print(f\"...not in WBPS mapping: {len(uniq_for[~uniq_for.index.isin(wbps_df.index)])}\")\n",
    "print(f\"Unique mappings from reverse Liftoff run (19 -> 18): {len(uniq_rev)}\")\n",
    "print(f\"...not in WBPS mapping: {len(uniq_rev[~uniq_rev.index.isin(wbps_df.index)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how many v19 genes are missed by both mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gffutils\n",
    "import os.path\n",
    "\n",
    "v19_path = \"data/from_WBPS/strongyloides_stercoralis.PRJNA930454.WBPS19.annotations.gff3\"\n",
    "\n",
    "if not os.path.exists(\"v19.db\"):\n",
    "    db = gffutils.create_db(v19_path, \"v19.db\", merge_strategy=\"create_unique\")\n",
    "else:\n",
    "    db = gffutils.FeatureDB(\"v19.db\")\n",
    "\n",
    "missing_v19_lo = set()\n",
    "missing_v19_wbps = set()\n",
    "for g in db.all_features(featuretype=\"gene\"):\n",
    "    g_id = g.id.split(\":\")[1]\n",
    "    if lo_df[lo_df.v19 == g_id].empty:\n",
    "        missing_v19_lo.add(g_id)\n",
    "    if wbps_df[wbps_df.v19 == g_id].empty:\n",
    "        missing_v19_wbps.add(g_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total WBPS19 genes: 12061\n",
      "Missing from Liftoff mappings: 3141\n",
      "Missing from WBPS mappings: 2279\n",
      "Missing from both: 1953\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total WBPS19 genes: {len(list(db.all_features(featuretype='gene')))}\")\n",
    "print(f\"Missing from Liftoff mappings: {len(missing_v19_lo)}\")\n",
    "print(f\"Missing from WBPS mappings: {len(missing_v19_wbps)}\")\n",
    "print(f\"Missing from both: {len(missing_v19_lo.intersection(missing_v19_wbps))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(gene_maps_dir, \"missing_v19_ids.txt\"), \"w\") as f:\n",
    "    for g_id in sorted(missing_v19_lo.intersection(missing_v19_wbps)):\n",
    "        f.write(f\"{g_id}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
